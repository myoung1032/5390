{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53439478",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e24fa685",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 523  \t# batch_size即每批训练的样本数量\n",
    "epochs = 20\t\t\t# 循环次数\n",
    "DEVICE=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")    #判断是否能在GPU上进行运算\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d137aebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(DEVICE)\n",
    "print(torch.backends.cudnn.enabled)\n",
    "# torch.backends.cudnn.enabled=False\n",
    "torch.backends.cudnn.enabled=True\n",
    "print(torch.backends.cudnn.enabled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c525b315",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(                 # vision.utils : 用于把形似 (3 x H x W) 的张量保存到硬盘中，给一个mini-batch的图像可以产生一个图像格网。\n",
    "        datasets.MNIST('data', train=True, download=True,\n",
    "                       transform=transforms.Compose([\n",
    "                           transforms.ToTensor(),       # 图像转化为Tensor\n",
    "                           transforms.Normalize((0.1307,), (0.3081,))       # 标准化\n",
    "                       ])),\n",
    "        batch_size=BATCH_SIZE, shuffle=True)            # shuffle() 方法将序列的所有元素随机排序\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bee67cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = torch.utils.data.DataLoader(\n",
    "        datasets.MNIST('data', train=False, transform=transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize((0.1307,), (0.3081,))\n",
    "                       ])),\n",
    "        batch_size=BATCH_SIZE, shuffle=True)            # shuffle() 方法将序列的所有元素随机排序\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4c4d5091",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module): # 继承model\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # 28x28\n",
    "        self.conv1=nn.Conv2d(1,12,5)         # 12, 24x24\n",
    "        self.conv2=nn.Conv2d(12, 20,3)       #20, 10x10\n",
    "        self.conv3=nn.Conv2d(20, 40,3)       #20, 10x10\n",
    "        self.batchnorm2d = nn.BatchNorm2d(40)\n",
    "        self.fc1=nn.Linear(40*8*8, 500)\n",
    "        self.fc2=nn.Linear(500, 10)\n",
    "    def forward(self, x):      #网络传播结构\n",
    "        in_size=x.size(0)# in_size 为 batch_size（一个batch中的Sample数）\n",
    "        # 卷积层 -> relu -> 最大池化\n",
    "        out = self.conv1(x)     # 24\n",
    "        out = F.relu(out)\n",
    "        out = F.max_pool2d(out, 2, 2)  # 12\n",
    "        out = self.conv2(out)  # 10\n",
    "        out = F.relu(out)\n",
    "        out = self.conv3(out)\n",
    "        out = F.relu(out)\n",
    "        out =  self.batchnorm2d(out)\n",
    "        out = out.view(in_size, -1)    # view()函数作用是将一个多行的Tensor,拼接成行。\n",
    "        # 输出前的预处理\n",
    "        out = self.fc1(out)\n",
    "        out = F.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        # softmax\n",
    "        out = F.log_softmax(out, dim=1)\n",
    "        # 返回值 out\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "03809baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net().to(DEVICE)\n",
    "optimizer = optim.Adam(model.parameters())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "01d02ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    model.eval()\n",
    "    for  epoch_i in range(epoch+1):\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            data, target = data, target      # CPU转GPU\n",
    "            data, target = data.to(device), target.to(device)   # CPU -> GPU\n",
    "\n",
    "            optimizer.zero_grad()               # 优化器清零\n",
    "            output = model(data)                # 由model，计算输出值\n",
    "            loss = F.nll_loss(output, target)   # 计算损失函数loss\n",
    "            loss.backward()                     # loss反向传播\n",
    "            optimizer.step()                    # 优化器优化\n",
    "            if(batch_idx+1)%30 == 0:            # 输出结果\n",
    "                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                    epoch_i, batch_idx * len(data), len(train_loader.dataset),\n",
    "                    100. * batch_idx / len(train_loader), loss.item()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "90afd0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, device, test_loader):\n",
    "    test_loss = 0                           # 损失函数初始化为0\n",
    "    correct = 0                             # correct 计数分类正确的数目\n",
    "    with torch.no_grad():           \n",
    "        for data, target in test_loader:    # 遍历所有的data和target\n",
    "            data, target = data.to(device), target.to(device)   # CPU -> GPU\n",
    "            output = model(data)            # output为预测值，由model计算出\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item()     ### 将一批的损失相加\n",
    "            pred = output.max(1, keepdim=True)[1]       ### 找到概率最大的下标\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)   # 总损失除数据集总数\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "18c3ee3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [15167/60000 (25%)]\tLoss: 0.354718\n",
      "Train Epoch: 0 [30857/60000 (51%)]\tLoss: 0.166337\n",
      "Train Epoch: 0 [46547/60000 (77%)]\tLoss: 0.143088\n",
      "Train Epoch: 1 [15167/60000 (25%)]\tLoss: 0.077669\n",
      "Train Epoch: 1 [30857/60000 (51%)]\tLoss: 0.086047\n",
      "Train Epoch: 1 [46547/60000 (77%)]\tLoss: 0.090376\n",
      "7.203686714172363\n",
      "\n",
      "Test set: Average loss: 0.0460, Accuracy: 9846/10000 (98%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "old=time.time()\n",
    "train(model, DEVICE, train_loader, optimizer, 1)\n",
    "print(time.time()-old)\n",
    "test(model, DEVICE, test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c684a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
